{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "count on the top words.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMmJB1pWzHAq2WDuxNcPql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandru-master/twitter-tweets-counter/blob/main/count_on_the_top_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ytvDmWTGPm",
        "outputId": "424f364e-5a51-4f0e-8e44-d353020a0956"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNZKorPBTIL2",
        "outputId": "13651113-9038-4286-ea93-4b4938968ab8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 281.4 MB 33 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 kB 44.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=0dd0e4b6864fbd53242e61852ae05eac6d15645050344e2b9533fa14bce67bfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BBkF9FR2S5LE"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "from pyspark import SparkConf,SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark.sql import Row,SQLContext\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from textblob import TextBlob\n",
        "import sys\n",
        "import requests\n",
        "import socket\n",
        "import pyspark.sql.functions as f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init()"
      ],
      "metadata": {
        "id": "R2lkxPLYS8U_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"words\").getOrCreate()"
      ],
      "metadata": {
        "id": "hGCrk_hoTn0b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "U_XD-Ur_TvFB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('tweet.csv', header=True)"
      ],
      "metadata": {
        "id": "JQTQiWqeUMY5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZZW-a9XUfUn",
        "outputId": "0cef3e68-ec61-440a-d6cb-c4071054317f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------+--------------------+\n",
            "|_c0|                Date|    User|               Tweet|\n",
            "+---+--------------------+--------+--------------------+\n",
            "|  0|2019-12-31 21:37:...|elonmusk|@engineers_feed @...|\n",
            "|  1|2019-12-31 06:59:...|elonmusk|@JohnnaCrider1 It...|\n",
            "|  2|2019-12-31 06:57:...|elonmusk|@newscientist Exp...|\n",
            "|  3|2019-12-31 02:27:...|elonmusk|@teslaownersSV @r...|\n",
            "|  4|2019-12-30 23:27:...|elonmusk|Rest in peace Syd...|\n",
            "|  5|2019-12-30 23:09:...|elonmusk|@kulpability @cle...|\n",
            "|  6|2019-12-30 23:00:...|elonmusk|@John_Gardi @Erda...|\n",
            "|  7|2019-12-30 22:44:...|elonmusk|@ShaneAppleton7 @...|\n",
            "|  8|2019-12-30 22:41:...|elonmusk|@JaneidyEve Heade...|\n",
            "|  9|2019-12-30 22:39:...|elonmusk|@EvaFoxU Biting o...|\n",
            "| 10|2019-12-30 10:05:...|elonmusk|@Teslarati Hard t...|\n",
            "| 11|2019-12-30 10:02:...|elonmusk|@BaconMan65 @Phil...|\n",
            "| 12|2019-12-30 10:00:...|elonmusk|@cleantechnica Wi...|\n",
            "| 13|2019-12-30 09:56:...|elonmusk|@EverydayTesla Ye...|\n",
            "| 14|2019-12-30 09:18:...|elonmusk|Barrel on dome ht...|\n",
            "| 15|2019-12-30 09:15:...|elonmusk|@ajtourville @cle...|\n",
            "| 16|2019-12-30 09:14:...|elonmusk|@SteveHamel16 @cl...|\n",
            "| 17|2019-12-30 08:51:...|elonmusk|@DonaldM38768041 ...|\n",
            "| 18|2019-12-30 08:49:...|elonmusk|@cleantechnica Se...|\n",
            "| 19|2019-12-30 08:03:...|elonmusk| @Erdayastronaut Yes|\n",
            "+---+--------------------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGOHlykPU6lF",
        "outputId": "1cb9de8f-aa82-483c-b1f2-4fe652a15dd8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(_c0='0', Date='2019-12-31 21:37:06+00:00', User='elonmusk', Tweet='@engineers_feed @physicsJ It‚Äôs a bit slow')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView('filter_view')"
      ],
      "metadata": {
        "id": "ymb1k2MeVLpc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter = spark.sql(\"\"\"select Tweet from filter_view\"\"\")\n"
      ],
      "metadata": {
        "id": "8XYyD21jVOWf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BqlykktVRjy",
        "outputId": "61ab67e2-00ae-4f3a-ce2c-1c501b8a312e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               Tweet|\n",
            "+--------------------+\n",
            "|@engineers_feed @...|\n",
            "|@JohnnaCrider1 It...|\n",
            "|@newscientist Exp...|\n",
            "|@teslaownersSV @r...|\n",
            "|Rest in peace Syd...|\n",
            "|@kulpability @cle...|\n",
            "|@John_Gardi @Erda...|\n",
            "|@ShaneAppleton7 @...|\n",
            "|@JaneidyEve Heade...|\n",
            "|@EvaFoxU Biting o...|\n",
            "|@Teslarati Hard t...|\n",
            "|@BaconMan65 @Phil...|\n",
            "|@cleantechnica Wi...|\n",
            "|@EverydayTesla Ye...|\n",
            "|Barrel on dome ht...|\n",
            "|@ajtourville @cle...|\n",
            "|@SteveHamel16 @cl...|\n",
            "|@DonaldM38768041 ...|\n",
            "|@cleantechnica Se...|\n",
            "| @Erdayastronaut Yes|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count the total number of words for each colums string values of  tweets"
      ],
      "metadata": {
        "id": "rWgsxLVqVw1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_filter.withColumn('wordCount', f.size(f.split(f.col('Tweet'), ' ')))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwoLo7dQVS8q",
        "outputId": "9fd1795e-e251-478d-873b-312fc39e356e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|               Tweet|wordCount|\n",
            "+--------------------+---------+\n",
            "|@engineers_feed @...|        6|\n",
            "|@JohnnaCrider1 It...|        5|\n",
            "|@newscientist Exp...|        4|\n",
            "|@teslaownersSV @r...|       18|\n",
            "|Rest in peace Syd...|        9|\n",
            "|@kulpability @cle...|        4|\n",
            "|@John_Gardi @Erda...|       34|\n",
            "|@ShaneAppleton7 @...|       11|\n",
            "|@JaneidyEve Heade...|       12|\n",
            "|@EvaFoxU Biting o...|       13|\n",
            "|@Teslarati Hard t...|       17|\n",
            "|@BaconMan65 @Phil...|        3|\n",
            "|@cleantechnica Wi...|        8|\n",
            "|@EverydayTesla Ye...|       15|\n",
            "|Barrel on dome ht...|        4|\n",
            "|@ajtourville @cle...|       11|\n",
            "|@SteveHamel16 @cl...|        6|\n",
            "|@DonaldM38768041 ...|        9|\n",
            "|@cleantechnica Se...|        5|\n",
            "| @Erdayastronaut Yes|        2|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Need to count same repeated words and which is the most \n",
        "# if we have the socket connection for the streamed data we can use trigger funtion for 300 seconds lyk.trigger(300 = seconds) and we can calclulate since we are using sample data set which is extracted from snscrape we will use with column methods instead of flattening the data we can count with splits"
      ],
      "metadata": {
        "id": "bgOUrTp6V_L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('word', f.explode(f.split(f.col('Tweet'), ' ')))\\\n",
        "    .groupBy('word')\\\n",
        "    .count()\\\n",
        "    .sort('count', ascending=False)\\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOYGyjdyWgGM",
        "outputId": "6d28c083-60a0-4120-9143-0e406857f58e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|           word|count|\n",
            "+---------------+-----+\n",
            "|             to| 1160|\n",
            "|             is|  817|\n",
            "|              a|  778|\n",
            "|            the|  761|\n",
            "|             of|  727|\n",
            "|          &amp;|  700|\n",
            "|             in|  597|\n",
            "|            for|  530|\n",
            "|         @Tesla|  418|\n",
            "|             be|  404|\n",
            "|             on|  386|\n",
            "|          Tesla|  376|\n",
            "|           will|  353|\n",
            "|            but|  336|\n",
            "|@Erdayastronaut|  311|\n",
            "|           with|  289|\n",
            "|           that|  264|\n",
            "|             it|  252|\n",
            "|              I|  227|\n",
            "|            are|  220|\n",
            "+---------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter.show(truncate=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ-5nQHJWkBL",
        "outputId": "399009c1-a0e9-4fee-909a-cae0592ff0af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Tweet                                                                                                                                                                                                                              |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|@engineers_feed @physicsJ It‚Äôs a bit slow                                                                                                                                                                                          |\n",
            "|@JohnnaCrider1 It‚Äôs not ready yet                                                                                                                                                                                                  |\n",
            "|@newscientist Explains üêà üé•                                                                                                                                                                                                       |\n",
            "|@teslaownersSV @rhoehn Thanks all Tesla club members for helping out! Looking forward to seeing you there tomorrow. ‚ù§Ô∏è                                                                                                             |\n",
            "|Rest in peace Syd Mead. Your art will endure.                                                                                                                                                                                      |\n",
            "|@kulpability @cleantechnica C tbh                                                                                                                                                                                                  |\n",
            "|@John_Gardi @Erdayastronaut Many ways to solve this problem, but the power requirements are much higher than aircraft control surfaces. When moving giant body flaps rapidly, achieving high power is much harder than high torque.|\n",
            "|@ShaneAppleton7 @Erdayastronaut Building prototypes is relatively easy, volume production is hard                                                                                                                                  |\n",
            "|@JaneidyEve Headed to Tesla Fremont factory tomorrow to help with vehicle deliveries                                                                                                                                               |\n",
            "|@EvaFoxU Biting off more than I can chew. Because I‚Äôm an optimistic fool.                                                                                                                                                          |\n",
            "|@Teslarati Hard to believe it‚Äôs almost time to retire Cargo Dragon after a decade of solid service                                                                                                                                 |\n",
            "|@BaconMan65 @PhiliChez Exactly                                                                                                                                                                                                     |\n",
            "|@cleantechnica Will talk about that on Q4 call                                                                                                                                                                                     |\n",
            "|@EverydayTesla Yeah, engineering is ~90% of my time at SpaceX &amp; about ~60% at Tesla                                                                                                                                            |\n",
            "|Barrel on dome https://t.co/kpSIJphbnk                                                                                                                                                                                             |\n",
            "|@ajtourville @cleantechnica Took me an embarrassingly long time to learn that                                                                                                                                                      |\n",
            "|@SteveHamel16 @cleantechnica Sounds about right ü§£ü§£                                                                                                                                                                               |\n",
            "|@DonaldM38768041 @Erdayastronaut Beyond awesome. He was the real deal.                                                                                                                                                             |\n",
            "|@cleantechnica Seems so long ago                                                                                                                                                                                                   |\n",
            "|@Erdayastronaut Yes                                                                                                                                                                                                                |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.parquet(\"count.parquet\")"
      ],
      "metadata": {
        "id": "LB13PaNQWptj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now successfully saved as parquet file"
      ],
      "metadata": {
        "id": "t5WiMao8YkAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def myConcat(*cols):\n",
        "    concat_columns = []\n",
        "    for c in cols[:-1]:\n",
        "        concat_columns.append(F.coalesce(c, F.lit(\"*\")))\n",
        "        concat_columns.append(F.lit(\" \"))  \n",
        "    concat_columns.append(F.coalesce(cols[-1], F.lit(\"*\")))\n",
        "    return F.concat(*concat_columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "fdN8eNtoYnRX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_text = df.withColumn(\"combined\", myConcat(*df.columns)).select(\"combined\")"
      ],
      "metadata": {
        "id": "pSqv4TGXE-TL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_text.show()"
      ],
      "metadata": {
        "id": "YTtANHJ4Fn6n",
        "outputId": "89ea8b75-d07a-4104-b2e1-2241bd8317ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            combined|\n",
            "+--------------------+\n",
            "|@engineers_feed @...|\n",
            "|@JohnnaCrider1 It...|\n",
            "|@newscientist Exp...|\n",
            "|@teslaownersSV @r...|\n",
            "|Rest in peace Syd...|\n",
            "|@kulpability @cle...|\n",
            "|@John_Gardi @Erda...|\n",
            "|@ShaneAppleton7 @...|\n",
            "|@JaneidyEve Heade...|\n",
            "|@EvaFoxU Biting o...|\n",
            "|@Teslarati Hard t...|\n",
            "|@BaconMan65 @Phil...|\n",
            "|@cleantechnica Wi...|\n",
            "|@EverydayTesla Ye...|\n",
            "|Barrel on dome ht...|\n",
            "|@ajtourville @cle...|\n",
            "|@SteveHamel16 @cl...|\n",
            "|@DonaldM38768041 ...|\n",
            "|@cleantechnica Se...|\n",
            "|@Erdayastronaut Y...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_text.coalesce(1).write.format(\"text\").option(\"header\", \"false\").mode(\"append\").save(\"output.txt\")"
      ],
      "metadata": {
        "id": "XoDH4RcoGR66"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(lines):\n",
        "    words = lines.select(explode(split(lines.value, \" \")).alias(\"word\"))\n",
        "    words = words.na.replace('', None)\n",
        "    words = words.na.drop()\n",
        "    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n",
        "    return words"
      ],
      "metadata": {
        "id": "RdV0rSBCGT91"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polarity_detection(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "def subjectivity_detection(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "def text_classification(words):\n",
        "    # polarity detection\n",
        "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
        "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
        "    # subjectivity detection\n",
        "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
        "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
        "    return words"
      ],
      "metadata": {
        "id": "xz_tl79WGc7s"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines =  spark.read.text('output.txt')"
      ],
      "metadata": {
        "id": "O6uo9N3IGrQP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    words = preprocessing(lines)\n",
        "    # text classification to define polarity and subjectivity\n",
        "    words = text_classification(words)\n"
      ],
      "metadata": {
        "id": "z1303vGzGjxt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words.show()"
      ],
      "metadata": {
        "id": "9HcVu27CI_NS",
        "outputId": "b35ba8df-9492-470a-9d49-2fe4e9040001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-------------------+\n",
            "|    word|            polarity|       subjectivity|\n",
            "+--------+--------------------+-------------------+\n",
            "|        |                 0.0|                0.0|\n",
            "|        |                 0.0|                0.0|\n",
            "|    It‚Äôs|                 0.0|                0.0|\n",
            "|       a|                 0.0|                0.0|\n",
            "|     bit|                 0.0|                0.0|\n",
            "|    slow|-0.30000000000000004|0.39999999999999997|\n",
            "|       6|                 0.0|                0.0|\n",
            "|        |                 0.0|                0.0|\n",
            "|    It‚Äôs|                 0.0|                0.0|\n",
            "|     not|                 0.0|                0.0|\n",
            "|   ready|                 0.2|                0.5|\n",
            "|     yet|                 0.0|                0.0|\n",
            "|       5|                 0.0|                0.0|\n",
            "|        |                 0.0|                0.0|\n",
            "|Explains|                 0.0|                0.0|\n",
            "|      üêà|                 0.0|                0.0|\n",
            "|      üé•|                 0.0|                0.0|\n",
            "|       4|                 0.0|                0.0|\n",
            "|        |                 0.0|                0.0|\n",
            "|        |                 0.0|                0.0|\n",
            "+--------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# we can maintain or write 300 seconds which means 5 minutes in streaming data so for that after i will get essential acccess for twitter i can do that"
      ],
      "metadata": {
        "id": "Z9k_sAU3LO65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# so kindly consider that this as model for it however the process flow need to flatter the data and need to map the data and streaming data need to load the file in the socket and we can get the output thanks by chandra prakash"
      ],
      "metadata": {
        "id": "JQ6JfZLXLSuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OO9NPC-DLkZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}