{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "count on the top words.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsvyQLIKQ8NBdtSXCbjuTS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandru-master/twitter-tweets-counter/blob/main/count_on_the_top_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ytvDmWTGPm",
        "outputId": "8c82c798-c2a7-4d84-947e-4443810b56c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNZKorPBTIL2",
        "outputId": "e18dd29f-c2bd-4891-ffd3-0af306c4ecd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 kB 53.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=cf727603d4569e38df3250729b5b85f1f8cc60ba6e20df34d55e1dd15b880fe3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BBkF9FR2S5LE"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "from pyspark import SparkConf,SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark.sql import Row,SQLContext\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from textblob import TextBlob\n",
        "import sys\n",
        "import requests\n",
        "import socket\n",
        "import pyspark.sql.functions as f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init()"
      ],
      "metadata": {
        "id": "R2lkxPLYS8U_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"words\").getOrCreate()"
      ],
      "metadata": {
        "id": "hGCrk_hoTn0b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "U_XD-Ur_TvFB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('tweet.csv', header=True)"
      ],
      "metadata": {
        "id": "JQTQiWqeUMY5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZZW-a9XUfUn",
        "outputId": "3a13a4d6-f905-4b25-a22d-d2875695271c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------+--------------------+\n",
            "|_c0|                Date|    User|               Tweet|\n",
            "+---+--------------------+--------+--------------------+\n",
            "|  0|2019-12-31 21:37:...|elonmusk|@engineers_feed @...|\n",
            "|  1|2019-12-31 06:59:...|elonmusk|@JohnnaCrider1 It...|\n",
            "|  2|2019-12-31 06:57:...|elonmusk|@newscientist Exp...|\n",
            "|  3|2019-12-31 02:27:...|elonmusk|@teslaownersSV @r...|\n",
            "|  4|2019-12-30 23:27:...|elonmusk|Rest in peace Syd...|\n",
            "|  5|2019-12-30 23:09:...|elonmusk|@kulpability @cle...|\n",
            "|  6|2019-12-30 23:00:...|elonmusk|@John_Gardi @Erda...|\n",
            "|  7|2019-12-30 22:44:...|elonmusk|@ShaneAppleton7 @...|\n",
            "|  8|2019-12-30 22:41:...|elonmusk|@JaneidyEve Heade...|\n",
            "|  9|2019-12-30 22:39:...|elonmusk|@EvaFoxU Biting o...|\n",
            "| 10|2019-12-30 10:05:...|elonmusk|@Teslarati Hard t...|\n",
            "| 11|2019-12-30 10:02:...|elonmusk|@BaconMan65 @Phil...|\n",
            "| 12|2019-12-30 10:00:...|elonmusk|@cleantechnica Wi...|\n",
            "| 13|2019-12-30 09:56:...|elonmusk|@EverydayTesla Ye...|\n",
            "| 14|2019-12-30 09:18:...|elonmusk|Barrel on dome ht...|\n",
            "| 15|2019-12-30 09:15:...|elonmusk|@ajtourville @cle...|\n",
            "| 16|2019-12-30 09:14:...|elonmusk|@SteveHamel16 @cl...|\n",
            "| 17|2019-12-30 08:51:...|elonmusk|@DonaldM38768041 ...|\n",
            "| 18|2019-12-30 08:49:...|elonmusk|@cleantechnica Se...|\n",
            "| 19|2019-12-30 08:03:...|elonmusk| @Erdayastronaut Yes|\n",
            "+---+--------------------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGOHlykPU6lF",
        "outputId": "459155dc-e326-421a-df0f-7fa0fcec801b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(_c0='0', Date='2019-12-31 21:37:06+00:00', User='elonmusk', Tweet='@engineers_feed @physicsJ It‚Äôs a bit slow')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView('filter_view')"
      ],
      "metadata": {
        "id": "ymb1k2MeVLpc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter = spark.sql(\"\"\"select Tweet from filter_view\"\"\")\n"
      ],
      "metadata": {
        "id": "8XYyD21jVOWf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BqlykktVRjy",
        "outputId": "31667cc7-8117-48e2-e0e8-321fb0fc18e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               Tweet|\n",
            "+--------------------+\n",
            "|@engineers_feed @...|\n",
            "|@JohnnaCrider1 It...|\n",
            "|@newscientist Exp...|\n",
            "|@teslaownersSV @r...|\n",
            "|Rest in peace Syd...|\n",
            "|@kulpability @cle...|\n",
            "|@John_Gardi @Erda...|\n",
            "|@ShaneAppleton7 @...|\n",
            "|@JaneidyEve Heade...|\n",
            "|@EvaFoxU Biting o...|\n",
            "|@Teslarati Hard t...|\n",
            "|@BaconMan65 @Phil...|\n",
            "|@cleantechnica Wi...|\n",
            "|@EverydayTesla Ye...|\n",
            "|Barrel on dome ht...|\n",
            "|@ajtourville @cle...|\n",
            "|@SteveHamel16 @cl...|\n",
            "|@DonaldM38768041 ...|\n",
            "|@cleantechnica Se...|\n",
            "| @Erdayastronaut Yes|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count the total number of words for each colums string values of  tweets"
      ],
      "metadata": {
        "id": "rWgsxLVqVw1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_filter.withColumn('wordCount', f.size(f.split(f.col('Tweet'), ' ')))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwoLo7dQVS8q",
        "outputId": "a85334e3-9d09-49d6-b794-ce1272125000"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|               Tweet|wordCount|\n",
            "+--------------------+---------+\n",
            "|@engineers_feed @...|        6|\n",
            "|@JohnnaCrider1 It...|        5|\n",
            "|@newscientist Exp...|        4|\n",
            "|@teslaownersSV @r...|       18|\n",
            "|Rest in peace Syd...|        9|\n",
            "|@kulpability @cle...|        4|\n",
            "|@John_Gardi @Erda...|       34|\n",
            "|@ShaneAppleton7 @...|       11|\n",
            "|@JaneidyEve Heade...|       12|\n",
            "|@EvaFoxU Biting o...|       13|\n",
            "|@Teslarati Hard t...|       17|\n",
            "|@BaconMan65 @Phil...|        3|\n",
            "|@cleantechnica Wi...|        8|\n",
            "|@EverydayTesla Ye...|       15|\n",
            "|Barrel on dome ht...|        4|\n",
            "|@ajtourville @cle...|       11|\n",
            "|@SteveHamel16 @cl...|        6|\n",
            "|@DonaldM38768041 ...|        9|\n",
            "|@cleantechnica Se...|        5|\n",
            "| @Erdayastronaut Yes|        2|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Need to count same repeated words and which is the most \n",
        "# if we have the socket connection for the streamed data we can use trigger funtion for 300 seconds lyk.trigger(300 = seconds) and we can calclulate since we are using sample data set which is extracted from snscrape we will use with column methods instead of flattening the data we can count with splits"
      ],
      "metadata": {
        "id": "bgOUrTp6V_L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('word', f.explode(f.split(f.col('Tweet'), ' ')))\\\n",
        "    .groupBy('word')\\\n",
        "    .count()\\\n",
        "    .sort('count', ascending=False)\\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOYGyjdyWgGM",
        "outputId": "836a12db-39b2-4092-99ce-4774b9882dbf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|           word|count|\n",
            "+---------------+-----+\n",
            "|             to| 1160|\n",
            "|             is|  817|\n",
            "|              a|  778|\n",
            "|            the|  761|\n",
            "|             of|  727|\n",
            "|          &amp;|  700|\n",
            "|             in|  597|\n",
            "|            for|  530|\n",
            "|         @Tesla|  418|\n",
            "|             be|  404|\n",
            "|             on|  386|\n",
            "|          Tesla|  376|\n",
            "|           will|  353|\n",
            "|            but|  336|\n",
            "|@Erdayastronaut|  311|\n",
            "|           with|  289|\n",
            "|           that|  264|\n",
            "|             it|  252|\n",
            "|              I|  227|\n",
            "|            are|  220|\n",
            "+---------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter.show(truncate=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ-5nQHJWkBL",
        "outputId": "48efaf86-463c-40ce-f972-280441c1f34c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Tweet                                                                                                                                                                                                                              |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|@engineers_feed @physicsJ It‚Äôs a bit slow                                                                                                                                                                                          |\n",
            "|@JohnnaCrider1 It‚Äôs not ready yet                                                                                                                                                                                                  |\n",
            "|@newscientist Explains üêà üé•                                                                                                                                                                                                       |\n",
            "|@teslaownersSV @rhoehn Thanks all Tesla club members for helping out! Looking forward to seeing you there tomorrow. ‚ù§Ô∏è                                                                                                             |\n",
            "|Rest in peace Syd Mead. Your art will endure.                                                                                                                                                                                      |\n",
            "|@kulpability @cleantechnica C tbh                                                                                                                                                                                                  |\n",
            "|@John_Gardi @Erdayastronaut Many ways to solve this problem, but the power requirements are much higher than aircraft control surfaces. When moving giant body flaps rapidly, achieving high power is much harder than high torque.|\n",
            "|@ShaneAppleton7 @Erdayastronaut Building prototypes is relatively easy, volume production is hard                                                                                                                                  |\n",
            "|@JaneidyEve Headed to Tesla Fremont factory tomorrow to help with vehicle deliveries                                                                                                                                               |\n",
            "|@EvaFoxU Biting off more than I can chew. Because I‚Äôm an optimistic fool.                                                                                                                                                          |\n",
            "|@Teslarati Hard to believe it‚Äôs almost time to retire Cargo Dragon after a decade of solid service                                                                                                                                 |\n",
            "|@BaconMan65 @PhiliChez Exactly                                                                                                                                                                                                     |\n",
            "|@cleantechnica Will talk about that on Q4 call                                                                                                                                                                                     |\n",
            "|@EverydayTesla Yeah, engineering is ~90% of my time at SpaceX &amp; about ~60% at Tesla                                                                                                                                            |\n",
            "|Barrel on dome https://t.co/kpSIJphbnk                                                                                                                                                                                             |\n",
            "|@ajtourville @cleantechnica Took me an embarrassingly long time to learn that                                                                                                                                                      |\n",
            "|@SteveHamel16 @cleantechnica Sounds about right ü§£ü§£                                                                                                                                                                               |\n",
            "|@DonaldM38768041 @Erdayastronaut Beyond awesome. He was the real deal.                                                                                                                                                             |\n",
            "|@cleantechnica Seems so long ago                                                                                                                                                                                                   |\n",
            "|@Erdayastronaut Yes                                                                                                                                                                                                                |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.parquet(\"count.parquet\")"
      ],
      "metadata": {
        "id": "LB13PaNQWptj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now successfully saved as parquet file"
      ],
      "metadata": {
        "id": "t5WiMao8YkAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fdN8eNtoYnRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}